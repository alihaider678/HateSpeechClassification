{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in e:\\study\\projects\\hatespeechclassification\\venv\\lib\\site-packages (2.0.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (2.2.1)\n",
      "Collecting numpy<2,>=1.26.0 (from pandas)\n",
      "  Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl (15.5 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.0.1\n",
      "    Uninstalling numpy-2.0.1:\n",
      "      Successfully uninstalled numpy-2.0.1\n",
      "Successfully installed numpy-1.26.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'E:\\STUDY\\Projects\\hatespeechclassification\\venv\\Lib\\site-packages\\~umpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'E:\\STUDY\\Projects\\hatespeechclassification\\venv\\Lib\\site-packages\\~umpy'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "datasets 2.18.0 requires fsspec[http]<=2024.2.0,>=2023.1.0, but you have fsspec 2024.6.0 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (3.8.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (4.50.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in e:\\study\\projects\\hatespeechclassification\\venv\\lib\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: seaborn in e:\\study\\projects\\hatespeechclassification\\venv\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in e:\\study\\projects\\hatespeechclassification\\venv\\lib\\site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from seaborn) (2.2.1)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from seaborn) (3.8.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.50.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from nltk) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from nltk) (4.66.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from click->nltk) (0.4.6)\n",
      "Requirement already satisfied: scikit-learn in e:\\study\\projects\\hatespeechclassification\\venv\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in e:\\study\\projects\\hatespeechclassification\\venv\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in e:\\study\\projects\\hatespeechclassification\\venv\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: tensorflow in e:\\study\\projects\\hatespeechclassification\\venv\\lib\\site-packages (2.17.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.17.0 in e:\\study\\projects\\hatespeechclassification\\venv\\lib\\site-packages (from tensorflow) (2.17.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in e:\\study\\projects\\hatespeechclassification\\venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in e:\\study\\projects\\hatespeechclassification\\venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in e:\\study\\projects\\hatespeechclassification\\venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in e:\\study\\projects\\hatespeechclassification\\venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in e:\\study\\projects\\hatespeechclassification\\venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in e:\\study\\projects\\hatespeechclassification\\venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in e:\\study\\projects\\hatespeechclassification\\venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in e:\\study\\projects\\hatespeechclassification\\venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (71.0.4)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in e:\\study\\projects\\hatespeechclassification\\venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.12.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in e:\\study\\projects\\hatespeechclassification\\venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in e:\\study\\projects\\hatespeechclassification\\venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.65.1)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in e:\\study\\projects\\hatespeechclassification\\venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.17.0)\n",
      "Requirement already satisfied: keras>=3.2.0 in e:\\study\\projects\\hatespeechclassification\\venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in e:\\study\\projects\\hatespeechclassification\\venv\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in e:\\study\\projects\\hatespeechclassification\\venv\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in e:\\study\\projects\\hatespeechclassification\\venv\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.12.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2024.6.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in e:\\study\\projects\\hatespeechclassification\\venv\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in e:\\study\\projects\\hatespeechclassification\\venv\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in e:\\study\\projects\\hatespeechclassification\\venv\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy \n",
    "!pip install pandas \n",
    "!pip install matplotlib \n",
    "!pip install seaborn \n",
    "!pip install nltk \n",
    "!pip install scikit-learn \n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding, SpatialDropout1D\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import string  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Download NLTK data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"E:/STUDY/Projects/hatespeechclassification/labeled_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inspect columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'count', 'hate_speech', 'offensive_language', 'neither',\n",
      "       'class', 'tweet'],\n",
      "      dtype='object')\n",
      "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
      "0           0      3            0                   0        3      2   \n",
      "1           1      3            0                   3        0      1   \n",
      "2           2      3            0                   3        0      1   \n",
      "3           3      3            0                   2        1      1   \n",
      "4           4      6            0                   6        0      1   \n",
      "\n",
      "                                               tweet  \n",
      "0  !!! RT @mayasolovely: As a woman you shouldn't...  \n",
      "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
      "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
      "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
      "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  \n"
     ]
    }
   ],
   "source": [
    "# Inspect columns\n",
    "print(df.columns)\n",
    "\n",
    "# Display first few rows to ensure data is loaded correctly\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Drop unnecessary columns and preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:16: SyntaxWarning: invalid escape sequence '\\['\n",
      "<>:17: SyntaxWarning: invalid escape sequence '\\S'\n",
      "<>:21: SyntaxWarning: invalid escape sequence '\\w'\n",
      "<>:16: SyntaxWarning: invalid escape sequence '\\['\n",
      "<>:17: SyntaxWarning: invalid escape sequence '\\S'\n",
      "<>:21: SyntaxWarning: invalid escape sequence '\\w'\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9416\\2431075624.py:16: SyntaxWarning: invalid escape sequence '\\['\n",
      "  words = re.sub('\\[.*?\\]', '', words)\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9416\\2431075624.py:17: SyntaxWarning: invalid escape sequence '\\S'\n",
      "  words = re.sub('https?://\\S+|www\\.\\S+', '', words)\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9416\\2431075624.py:21: SyntaxWarning: invalid escape sequence '\\w'\n",
      "  words = re.sub('\\w*\\d\\w*', '', words)\n"
     ]
    }
   ],
   "source": [
    "columns_to_drop = ['Unnamed: 0', 'count', 'hate_speech', 'offensive_language', 'neither']\n",
    "df = df.drop(columns=[col for col in columns_to_drop if col in df.columns])\n",
    "\n",
    "if 'class' in df.columns:\n",
    "    df['class'] = df['class'].replace({0: 1, 2: 0})\n",
    "    df = df.rename(columns={'class': 'label'})\n",
    "else:\n",
    "    print(\"Error: 'class' column not found in the DataFrame.\")\n",
    "    raise KeyError(\"'class' column not found in the DataFrame\")\n",
    "\n",
    "stemmer = nltk.SnowballStemmer(\"english\")\n",
    "stopword = set(stopwords.words('english'))\n",
    "\n",
    "def data_cleaning(words):\n",
    "    words = str(words).lower()\n",
    "    words = re.sub('\\[.*?\\]', '', words)\n",
    "    words = re.sub('https?://\\S+|www\\.\\S+', '', words)\n",
    "    words = re.sub('<.*?>+', '', words)\n",
    "    words = re.sub('[%s]' % re.escape(string.punctuation), '', words)\n",
    "    words = re.sub('\\n', '', words)\n",
    "    words = re.sub('\\w*\\d\\w*', '', words)\n",
    "    words = [word for word in words.split(' ') if word not in stopword]\n",
    "    words = \" \".join(words)\n",
    "    words = [stemmer.stem(word) for word in words.split(' ')]\n",
    "    return \" \".join(words)\n",
    "\n",
    "df['tweet'] = df['tweet'].apply(data_cleaning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['tweet']\n",
    "y = df['label']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 50000\n",
    "max_len = 300\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "sequences = tokenizer.texts_to_sequences(x_train)\n",
    "sequences_matrix = pad_sequences(sequences, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\STUDY\\Projects\\hatespeechclassification\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_words, 100, input_length=max_len))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer=RMSprop(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 615ms/step - accuracy: 0.8192 - loss: 0.4353 - val_accuracy: 0.9333 - val_loss: 0.1616\n",
      "Epoch 2/5\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 625ms/step - accuracy: 0.9406 - loss: 0.1562 - val_accuracy: 0.9489 - val_loss: 0.1244\n",
      "Epoch 3/5\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 663ms/step - accuracy: 0.9604 - loss: 0.1080 - val_accuracy: 0.9521 - val_loss: 0.1196\n",
      "Epoch 4/5\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 798ms/step - accuracy: 0.9720 - loss: 0.0825 - val_accuracy: 0.9516 - val_loss: 0.1227\n",
      "Epoch 5/5\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 721ms/step - accuracy: 0.9778 - loss: 0.0704 - val_accuracy: 0.9524 - val_loss: 0.1255\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(sequences_matrix, y_train, batch_size=128, epochs=5, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 56ms/step - accuracy: 0.9436 - loss: 0.1438\n"
     ]
    }
   ],
   "source": [
    "test_sequences = tokenizer.texts_to_sequences(x_test)\n",
    "test_sequences_matrix = pad_sequences(test_sequences, maxlen=max_len)\n",
    "accr = model.evaluate(test_sequences_matrix, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(\"model.h5\")\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
